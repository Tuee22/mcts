# Docker environment configuration
# Copy this to .env and uncomment the configuration you want

# For CPU build (default):
# TARGET=cpu
# PLATFORM=linux/amd64  
# PORT=8000

# For CUDA build (NVIDIA GPU systems):
# TARGET=cuda
# PLATFORM=linux/amd64
# NVIDIA_VISIBLE_DEVICES=all
# PORT=8000

# For ARM64 build (Apple Silicon, etc):
# TARGET=cpu
# PLATFORM=linux/arm64
# PORT=8000

# Advanced configuration options:
# TARGET                  - Build target: cpu or cuda
# PLATFORM                - Docker platform: linux/amd64, linux/arm64
# NVIDIA_VISIBLE_DEVICES  - GPU devices for CUDA builds (all, 0, 1, etc)
# PORT                    - External port mapping (default: 8000)

# Usage examples:
# 1. CPU build (AMD64):    docker compose up -d
# 2. CPU build (ARM64):    Set PLATFORM=linux/arm64 in .env, then: docker compose up -d  
# 3. CUDA build:           Set TARGET=cuda and NVIDIA_VISIBLE_DEVICES=all in .env, then:
#                          docker run --rm --gpus all $(docker compose config | grep "image:" | awk '{print $2}') nvidia-smi
#                          docker compose run --rm --gpus all mcts
# 4. Custom port:          Set PORT=9000 in .env, then: docker compose up -d

# Notes:
# - CUDA builds require NVIDIA Docker runtime and compatible GPU
# - ARM64 builds use architecture-specific optimizations
# - The nvidia/cuda:12.6.2-devel-ubuntu22.04 base image is used for CUDA builds
# - Cross-platform builds may require Docker buildx setup